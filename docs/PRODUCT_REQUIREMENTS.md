## **产品需求文档 (PRD) - “ZSCE Agent”**

**版本**: 1.1
**文档状态**: 迭代中

### 1. 项目愿景与目标
在与大型语言模型（LLM）协作编程时，开发者常常需要花费大量精力来提供和维护上下文（Context），导致效率低下和结果不可控。

本项目旨在开发一个名为 **“ZSCE (Zero-Shot Context Engineering) Agent”** 的智能应用。其核心目标是：让开发者能用最简单、最高层的自然语言命令，通过 Agent 的自动化上下文工程和多智能体协作，生成高质量、与开发者真实意图高度对齐的最终代码产出。核心是为用户提供一个“永不失忆”的、高度可靠的AI开发助理。

### 2. 核心问题/用户痛点
*   **上下文缺失与失忆**: 普通AI工具的上下文窗口有限，导致在多轮或长期任务中“忘记”之前的对话、代码和项目状态。
*   **手动提供上下文繁琐**: 开发者需要手动复制粘贴大量代码和文件内容，过程枯燥且容易出错。
*   **结果不可控与“造假”**: 单一LLM的输出可能存在“幻觉”，或为了达成表面目标而选择“捷径”（如生成假数据、假实现），缺乏批判和审查机制。
*   **AI串通风险**: 在多Agent系统中，如果设计不当，多个Agent可能共享思维盲点，导致“串通”或“自我欺骗”。

### 3. 核心功能需求 (Features)
| 优先级 | 功能模块 | 描述 |
| :--- | :--- | :--- |
| **P0** | **混合记忆系统** | 通过工作记忆（动态Prompt）、情景记忆（持久化日志）和语义记忆（向量化RAG）相结合，为Agent提供“永不失忆”的长期项目记忆能力。 |
| **P0** | **多智能体协作核心 (MCP)** | 实现一个内置“高手”(Developer)和“看门狗”(Reviewer)角色的协作平台，内置“交叉验证”机制。 |
| **P0** | **测试驱动开发 (TDD) 工作流** | “看门狗”根据用户需求，首先生成一个严格的、覆盖边界条件的失败测试用例，作为“高手”的开发目标。 |
| **P1** | **多轮对抗性辩论机制** | “高手”和“看门狗”进行多轮“代码-审查-修改”循环。循环有固定轮数上限，以防无限循环。 |
| **P1** | **人类仲裁机制** | 在辩论循环结束仍未达成共识时，系统必须暂停，向用户暴露分歧点，并请求人类做出最终决策。 |
| **P1** | **动态“宪法”生成** | Agent 在任务开始前分析代码库，动态生成本次任务需遵守的规则，并为不同角色注入独立的、目标相反的“个人宪法”，以防串通。 |

### 4. 非功能性需求
*   **可扩展性**: 方便未来增加新的角色或支持新的编程语言。
*   **性能与成本**: Agent应具备模型选择能力，为不同复杂度的任务（如代码生成 vs. 代码审查）匹配不同成本和性能的模型。
*   **上下文管理**: 必须有能力处理超出LLM单次输入限制的大型项目，采用过滤、压缩、RAG等策略有效管理上下文。
*   **交叉验证与反共谋**: 系统设计需从根本上防止Agent间的“共享偏见”和“串通造假”，例如通过模型多样性（为不同Agent分配不同LLM）等手段。

### 5. AI 伦理与安全设计 (Ethical & Safety Design)
*   **代码安全保障**: “看门狗”Agent的核心职责之一是利用静态分析工具检查代码中常见的安全漏洞。
*   **偏见与公平性**: Agent在生成所有内容时，必须使用中立和包容的语言。
*   **透明度与可解释性**: Agent的决策过程（辩论历史、工具使用记录）必须被清晰地记录下来。系统应采用“宏观可解释性”方法，让用户理解Agent的行为逻辑，而非解释LLM的内部参数。
*   **人类最终控制权**: 用户在关键节点拥有最终批准权和否决权。
*   **禁止破坏性操作**: Agent被严格禁止执行任何不可逆的破坏性操作，除非得到用户的多步显式确认。